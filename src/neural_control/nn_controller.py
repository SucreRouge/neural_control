"""
Neural Network Controller


--- USAGE ---

Use give_new_state and give_new_reference as explained in
the example nodes. They will upack data and call get_wrench,
which will publish a wrench that best tends the current state
to the reference state.

It is published as a WrenchStamped message under the topic
name chosen on initialization. The portion of that wrench
generated by the neural network alone is similarly publishable
for examination (use the whole wrench to control the vehicle).

The class can be configured for a 6, 3, or 2 degree of
freedom robot. See __init__ documentation for more details
on how to configure.

It is critical that under abnormal operation, the neural
network's learning is haulted. The controller subscribes
to the topic /nnc_learn (ROS std bool message) to either
start/continue learning (True) or hault learning (False).
It initializes False. Some situations in which you want
to hault and later resume learning are if:
- any actuators are saturated (seriously)
- someone is harassing the robot
- your submarine is surfacing

Publish True to the topic /nnc_reset (ROS std bool message)
to clear the NN back to zero weights.

If you want to not use the neural network portion of this
controller, manually override the attribute just_PD = True.
The controller will reduce to a simple proportional-derivative.

A learning controller like this must be given a continuous
trajectory to track, meaning that the reference cannot have
large discontinuous jumps. You need to show the NN behavior
that the vehicle is capable of (some desired trajectory)
and not behavior that is impossible (teleportation).

Reference frames follow ROS convention unless otherwise stated.
- position is in world frame
- orientation represents the transform from body to world
- velocity and angular velocity are in body frame
- wrenches and accelerations are in body frame

Units are always base-SI (m, kg, s).


--- THEORY ---

A single layer neural network (NN) is used to generate a
feedforward term for a typical state-feedback (PD) controller.
The system is assumed to have error dynamics of the form,

edot = f(x) - u,      i.e. control-affine, holonomic, and time-invariant

The input to the NN is the full state x, and the output is
the estimated system dynamics, f(x). Thus choose,

u = e + NN      ==>      edot = -e + epsilon

where epsilon is the current estimation error of the NN.

The NN weights are updated to minimize e, not epsilon.
This guarantees Lyapunov stability during the learning.

The minimum size of epsilon (ball of convergence) depends
on the structure of the NN itself (size and basis functions).

Reference: http://www.pdx.edu/sites/www.pdx.edu.sysc/files/media_assets/SySc576_FrankLewisNNsControl.pdf

---

Author: Jason Nezvadovitz

"""

################################################# DEPENDENCIES

# Math
from __future__ import division
import numpy as np
import numpy.linalg as npl
import tf.transformations as trns

# Communication
import rospy
from std_msgs.msg import Bool
from geometry_msgs.msg import WrenchStamped

################################################# PRIMARY CLASS

class NN_controller:
	"""
	See nn_controller.py module documentation for more details.

	"""

	def __init__(self, dof, kp, kd, kv, kw, N, sig, nn_limit,
				 wrench_topic='/wrench', neuralwrench_topic='/neuralwrench'):
		"""
		Initialization.

		dof: Number of degrees of freedom relevant to the system.
			 Feedback gains and nn_limit are expected accordingly.
			 dof == 6  => (x, y, z, roll, pitch, yaw)
			 dof == 3  => (x, y, yaw)
			 dof == 2  => (x, y)

		kp:  Proportional feedback gains.
		kd:  Derivative feedback gains.
		kv:  Input-side learning gain (scalar).
		kw:  Output-side learning gain (scalar).

		N:   Number of neurons.
		sig: Neuron basis function. As of now, can only be 'tanh'.
		nn_limit: Limit on NN feedforward wrench.

		wrench_topic: String name of topic to publish full wrench to.
					  This is the wrench the vehicle should apply.

		neuralwrench_topic: String name of topic to publush the portion
							or component of the full wrench that the NN
							alone has generated. Nice to examine.

		"""
		# Dof-dependent configuration
		self.dof = int(dof)
		if self.dof == 6:
			self.unpack = self.unpack_6dof
			self.vectorize = lambda arr: arr
			self.unvectorize = lambda vec: vec
		elif self.dof == 3:
			self.unpack = self.unpack_3dof
			self.vectorize = lambda arr: np.concatenate((arr[:2], np.zeros(3), [arr[2]]))
			self.unvectorize = lambda vec: np.concatenate((vec[:2], [vec[5]]))
		elif self.dof == 2:
			self.unpack = self.unpack_2dof
			self.vectorize = lambda arr: np.concatenate((arr, np.zeros(4)))
			self.unvectorize = lambda vec: vec[:2]
		else:
			raise ValueError("Unsupported dof number requested.")

		# Controller parameters
		self.set_gains(kp, kd, kv, kw)
		self.set_network(N, sig, nn_limit)

		# Memory initializations
		self.dt = 0  # time since last call
		self.last_timestamp = 0  # previous call's timestamp
		self.reset_learning(Bool(data=True))  # initializes NN weights to zeros

		# Flags
		self.learn = False
		self.just_PD = False
		self._got_first_reference = False

		# ROS
		rospy.Subscriber('/nnc_learn', Bool, self.toggle_learning)
		rospy.Subscriber('/nnc_reset', Bool, self.reset_learning)
		self.wrench_pub = rospy.Publisher(wrench_topic, WrenchStamped, queue_size=0)
		self.neuralwrench_pub = rospy.Publisher(neuralwrench_topic, WrenchStamped, queue_size=0)

		print("NN controller active.\nReady to begin learning.")

########################

	def get_wrench(self):
		"""
		Publishes and returns wrench for this instant. Also
		publishes the neural network component of said wrench.

		"""
		# Translational component of positional error, converted to body frame
		E_pos_lin = self.R.T.dot(self.p_ref - self.p)
		# Angular component of positional error, converted to body frame
		E_pos_ang = self.R.T.dot(self.qerror(self.q, self.q_ref))
		# Positional error, now in body frame
		E_pos = np.concatenate((E_pos_lin, E_pos_ang))
		# Velocity error, inherently in body frame
		E_vel = np.concatenate((self.v_ref - self.v, self.w_ref - self.w))
		# Tracking error
		E_tra = self.kr*E_pos + E_vel

		# Control law
		if self.just_PD:

			self.u = self.kp*E_pos + self.kd*E_vel
		
		else:

			self.u = self.kp*E_pos + self.kd*E_vel + self.y

			# Adapt NN
			if self.learn:
				# Compute weight rates-of-change
				VTx = self.V.T.dot(self.x)
				Wdot = self.kw * (np.outer(self.sig(VTx), self.unvectorize(E_tra)))
				Vdot = self.kv * (np.outer(self.x, self.unvectorize(E_tra)).dot(self.W.T).dot(self.sigp(VTx)))
				# Step weights forward
				self.W = self.W + (Wdot * self.dt)
				self.V = self.V + (Vdot * self.dt)
				# Vectorize the NN output (still in world frame)
				y_world = self.vectorize(self.W.T.dot(self.sig(self.V.T.dot(self.x))))
				# Convert to body frame and clip
				self.y = np.clip(np.concatenate((self.R.T.dot(y_world[:3]), self.R.T.dot(y_world[3:]))),
								 -self.nn_limit, self.nn_limit)

		# Construct total wrench and publish
		wrench = WrenchStamped()
		wrench.header.frame_id = '/base_link'
		wrench.header.stamp = rospy.Time.from_sec(self.last_timestamp)
		wrench.wrench.force.x = self.u[0]
		wrench.wrench.force.y = self.u[1]
		wrench.wrench.force.z = self.u[2]
		wrench.wrench.torque.x = self.u[3]
		wrench.wrench.torque.y = self.u[4]
		wrench.wrench.torque.z = self.u[5]
		self.wrench_pub.publish(wrench)

		# Also publish neural network component alone
		neuralwrench = WrenchStamped()
		neuralwrench.header.frame_id = '/base_link'
		neuralwrench.header.stamp = rospy.Time.from_sec(self.last_timestamp)
		neuralwrench.wrench.force.x = self.y[0]
		neuralwrench.wrench.force.y = self.y[1]
		neuralwrench.wrench.force.z = self.y[2]
		neuralwrench.wrench.torque.x = self.y[3]
		neuralwrench.wrench.torque.y = self.y[4]
		neuralwrench.wrench.torque.z = self.y[5]
		self.neuralwrench_pub.publish(neuralwrench)

		return self.u

########################

	def set_gains(self, kp=None, kd=None, kv=None, kw=None):
		"""
		Sets gains. Each argument defaults to not changing.

		kp: Proportional feedback gains.
		kd: Derivative feedback gains.
		kv: Input-side learning gain.
		kw: Output-side learning gain.

		Gains kp and kd must have self.dof number of elements.
		Gains kv and kw are scalars.

		"""
		if kp is not None:
			assert len(kp) == self.dof
			self.kp = self.vectorize(np.array(kp, dtype=np.float32))

		if kd is not None:
			assert len(kd) == self.dof
			self.kd = self.vectorize(np.array(kd, dtype=np.float32))

		if kv is not None:
			self.kv = float(kv)

		if kw is not None:
			self.kw = float(kw)

		# Gain ratio used in NN update law
		self.kr = np.zeros(6)
		for i in xrange(6):
			if self.kd[i]:
				self.kr[i] = self.kp[i] / self.kd[i]

########################

	def set_network(self, N=None, sig=None, nn_limit=None):
		"""
		Set-up neural network. Each argument defaults to not changing.

		N:        Number of neurons.
		sig:      Neuron basis function. As of now, can only be 'tanh'.
		nn_limit: Limit on NN feedforward wrench.

		The wrench nn_limit must have self.dof number of elements.

		"""
		if N is not None:
			self.N = int(N)

		if sig is not None:
			if sig == 'tanh':
				self.sig = lambda x: np.concatenate(([1], np.tanh(x)))
				self.sigp = lambda x: np.tile(1/(np.cosh(x)**2), (self.N+1, 1))
			else:
				raise ValueError("Unsupported neuron basis function requested.")

		if nn_limit is not None:
			assert len(nn_limit) == self.dof
			self.nn_limit = self.vectorize(np.array(nn_limit, dtype=np.float32))

########################

	def toggle_learning(self, bool_msg):
		"""
		Callback for the /nnc_learn topic. Sets
		self.learn to True or False depending
		on the Bool message.

		"""
		self.learn = bool_msg.data
		if self.learn:
			print("NN controller is learning.")
		else:
			print("NN controller haulted learning.")

########################

	def reset_learning(self, bool_msg):
		"""
		Use this function to reset all NN weights to zeros.

		"""
		if bool_msg.data:
			print("NN controller reset.")
			self.V = np.zeros((2*self.dof + 1, self.N))  # input-side weights
			self.W = np.zeros((self.N + 1, self.dof))  # output-side weights
			# self.V = np.zeros((2*6 + 1, self.N))  # input-side weights
			# self.W = np.zeros((self.N + 1, 6))  # output-side weights
			self.y = np.zeros(6)  # neural network wrench (body frame)

########################

	def give_new_state(self, pose, twist, timestamp_secs):
		"""
		Callback for when a new state is received.
		Pass it the ROS pose, twist, and timestamp
		parts of whatever message you're working with.
		The timestamp must be in seconds.

		"""
		# Unpack into vectors for controller math
		p, q, R, v, w, x = self.unpack(pose.position, pose.orientation,
									   twist.linear, twist.angular)
		self.p = p
		self.q = q
		self.R = R
		self.v = v
		self.w = w
		self.x = x

		# Store timestep since last update
		if self.last_timestamp:
			self.dt = timestamp_secs - self.last_timestamp
		self.last_timestamp = timestamp_secs

		# Compute and publish wrench
		if self._got_first_reference:
			self.get_wrench()
		else:
			print("Waiting for first reference to track...")

########################

	def give_new_reference(self, pose, twist):
		"""
		Callback for when a new reference is received.
		Pass it the ROS pose and twist parts of whatever
		message you're working with.

		"""
		# Unpack into vectors for controller math
		p, q, R, v, w, x = self.unpack(pose.position, pose.orientation,
									   twist.linear, twist.angular)
		self.p_ref = p
		self.q_ref = q
		self.R_ref = R
		self.v_ref = v
		self.w_ref = w
		self.x_ref = x

		self._got_first_reference = True

########################

	def qerror(self, q, q_ref):
		"""
		Returns rotation vector representing the
		orientation error from quaternion q to q_ref.

		"""
		# Quaternion from q to q_ref
		qdiff = trns.quaternion_multiply(self.q_ref, trns.quaternion_inverse(self.q))
		# Renormalize for accuracy
		qdiff = trns.unit_vector(qdiff)
		# If "amount of rotation" is negative, flip quaternion
		if qdiff[3] < 0:
			qdiff = -qdiff
		# Extract axis
		axis = trns.unit_vector(qdiff[:3])
		# Extract angle
		angle = 2 * np.arccos(qdiff[3])
		# Return rotvec
		return angle * axis

########################

	def unpack_6dof(self, position, orientation, linvel_body, angvel_body):
		p = np.array([position.x, position.y, position.z])
		q = np.array([orientation.x, orientation.y, orientation.z, orientation.w])
		R = trns.quaternion_matrix(q)[:3, :3]
		v = np.array([linvel_body.x, linvel_body.y, linvel_body.z])
		w = np.array([angvel_body.x, angvel_body.y, angvel_body.z])
		euler = trns.euler_from_quaternion(q)
		x = np.concatenate(([1], p, euler, R.dot(v), R.dot(w)))
		return (p, q, R, v, w, x)

########################

	def unpack_3dof(self, position, orientation, linvel_body, angvel_body):
		p = np.array([position.x, position.y, 0])
		q = np.array([orientation.x, orientation.y, orientation.z, orientation.w])
		R = trns.quaternion_matrix(q)[:3, :3]
		v = np.array([linvel_body.x, linvel_body.y, 0])
		w = np.array([0, 0, angvel_body.z])
		yaw = trns.euler_from_quaternion(q)[2]
		x = np.concatenate(([1], p[:2], [yaw], R.dot(v)[:2], [R.dot(w)[2]]))
		# x = np.concatenate(([1], p[:2], [0], [0, 0, yaw], R.dot(v)[:2], [0], [0, 0, R.dot(w)[2]]))
		return (p, q, R, v, w, x)

########################

	def unpack_2dof(self, position, orientation, linvel_body, angvel_body):
		p = np.array([position.x, position.y, 0])
		q = np.array([0, 0, 0, 1])
		R = np.eye(3)
		v = np.array([linvel_body.x, linvel_body.y, 0])
		w = np.zeros(3)
		x = np.concatenate(([1], p[:2], v[:2]))
		# x = np.concatenate(([1], p[:2], [0], v[:2], np.zeros(7)))
		return (p, q, R, v, w, x)
